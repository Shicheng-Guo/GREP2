\nonstopmode{}
\documentclass[letterpaper]{book}
\usepackage[times,inconsolata,hyper]{Rd}
\usepackage{makeidx}
\usepackage[utf8,latin1]{inputenc}
% \usepackage{graphicx} % @USE GRAPHICX@
\makeindex{}
\begin{document}
\chapter*{}
\begin{center}
{\textbf{\huge Package `GREP2'}}
\par\bigskip{\large \today}
\end{center}
\begin{description}
\raggedright{}
\item[Title]\AsIs{GEO RNA-seq Experiments Processing Pipeline}
\item[Version]\AsIs{0.0.0.99}
\item[Author]\AsIs{Naim Mahi [cre,aut], Mario Medvedovic [aut, ctb]}
\item[Maintainer]\AsIs{Naim Mahi }\email{naim.al.mahi@gmail.com}\AsIs{}
\item[Description]\AsIs{An R based comprehensive pipeline to download and process GEO RNA-seq data.}
\item[Depends]\AsIs{R (>= 3.4.1)}
\item[Imports]\AsIs{XML, rentrez, RCurl, GEOquery, Biobase, parallel, tximport,
EnsDb.Hsapiens.v86, EnsDb.Rnorvegicus.v79, EnsDb.Mmusculus.v79,
AnnotationDbi, org.Hs.eg.db, org.Mm.eg.db, org.Rn.eg.db, utils,
GenomicFeatures}
\item[Suggests]\AsIs{knitr, BiocStyle, RMySQL, ensembldb, rmarkdown}
\item[License]\AsIs{GPL-3}
\item[VignetteBuilder]\AsIs{rmarkdown}
\item[LazyData]\AsIs{true}
\item[biocViews]\AsIs{GEO, RNASeq, GeneExpression, Software, DataImport,
Preprocessing, QualityControl, Alignment}
\item[RoxygenNote]\AsIs{6.0.1}
\end{description}
\Rdcontents{\R{} topics documented:}
\inputencoding{utf8}
\HeaderA{build\_index}{Build index for mapping using Salmon}{build.Rul.index}
%
\begin{Description}\relax
\code{build\_index} for mapping reads using Salmon.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
build_index(species = c("human", "mouse", "rat"), kmer = 31, destdir,
  ens_release = 92)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{species}] name of the species. Only \code{'human'}, \code{'mouse'}, and \code{'rat'} are allowed to use.

\item[\code{kmer}] k-mer size for indexing. default is 31. See \code{'Salmon'} for details.

\item[\code{destdir}] directory to save index files.

\item[\code{ens\_release}] version of Ensembl release.
\end{ldescription}
\end{Arguments}
%
\begin{References}\relax
Rob Patro, Geet Duggal, Michael I. Love, Rafael A. Irizarry, and Carl Kingsford (2017):
Salmon provides fast and bias-aware quantification of transcript expression. Nature methods, 14(4), 417.
\url{https://www.nature.com/articles/nmeth.4197}
\end{References}
%
\begin{Examples}
\begin{ExampleCode}

build_index(species="human", kmer=31, destdir=".", ens_release=92)

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{get\_fastq}{Download fastq files}{get.Rul.fastq}
%
\begin{Description}\relax
\code{get\_fastq} downloads fastq files using SRA toolkit. 
We recommend using Aspera for fast downloading. You need to install Aspera(\url{http://www.asperasoft.com/}) for using \code{ascp} option.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
get_fastq(srr_id, library_layout = c("SINGLE", "PAIRED"),
  get_sra_file = FALSE, sra_files_dir = NULL, n_thread, destdir)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{srr\_id}] SRA run accession ID.

\item[\code{library\_layout}] layout of the library used. Either \code{'SINGLE'} or \code{'PAIRED'}.

\item[\code{get\_sra\_file}] logical, whether to download SRA file first and get fastq files afterwards or directly download fastq files.

\item[\code{sra\_files\_dir}] directory where SRA files are saved. If you use \code{get\_sra\_file=FALSE} then \code{sra\_files\_dir=NULL}.

\item[\code{n\_thread}] number of cores to use.

\item[\code{destdir}] directory where all the results will be saved.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A single fastq file will be generated for SINGLE end reads and two files for PAIRED end reads.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
get_fastq(srr_id="SRR6324192", library_layout="SINGLE", get_sra_file=FALSE, 
sra_files_dir=NULL, n_thread=2, destdir=".")

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{get\_metadata}{Download metadata from GEO and SRA}{get.Rul.metadata}
%
\begin{Description}\relax
Download metadata from GEO and SRA
\end{Description}
%
\begin{Usage}
\begin{verbatim}
get_metadata(geo_series_acc)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{geo\_series\_acc}] GEO series accession ID.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a list of GEO and SRA metadata.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}

get_metadata(geo_series_acc="GSE107363")

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{get\_srr}{Download SRA run files}{get.Rul.srr}
%
\begin{Description}\relax
\code{get\_srr} downloads SRA files using Aspera (\url{http://www.asperasoft.com/}) or FTP. 
We recommend using Aspera for fast downloading. You need to install Aspera for using \code{ascp} option.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
get_srr(srr_id, destdir, ascp = TRUE, prefetch_workspace, ascp_path)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{srr\_id}] SRA run accession ID.

\item[\code{destdir}] directory where all the results will be saved.

\item[\code{ascp}] logical, whether to use Aspera for downloading SRA files.

\item[\code{prefetch\_workspace}] directory where SRA run files will be downloaded. This parameter is needed if \code{ascp=TRUE}. 
The location of this directory can be found by going to the aspera directory (/.aspera/connect/bin/) and typing \code{'vdb-config -i'}.
A new window will pop-up and under the \code{'Workspace Name'}, you will find the location. Usually the default is \code{'/home/username/ncbi/public'}.

\item[\code{ascp\_path}] path to the Aspera software.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
SRA run accession file with extension ".sra". If you use \code{ascp=TRUE}, then downloaded files will be saved under \code{'/prefetch\_workspace/sra'} directory. 
If \code{ascp=FALSE}, then files will be saved in the \code{'destdir'}
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
get_srr(srr_id="SRR6324192", destdir=".", ascp=TRUE, 
prefetch_workspace="path_to_prefetch_workspace", ascp_path="path_to_aspera")

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{process\_geo\_rnaseq}{A complete pipeline to process GEO RNA-seq data}{process.Rul.geo.Rul.rnaseq}
%
\begin{Description}\relax
\code{process\_geo\_rnaseq} downloads and processes GEO RNA-seq data for a given GEO series accession ID. It filters metadata for RNA-seq samples only. 
We use SRA toolkit for downloading SRA data, Trimmomatic for read trimming (optional), and Salmon for read mapping.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
process_geo_rnaseq(geo_series_acc, destdir, ascp = TRUE, prefetch_workspace,
  ascp_path, get_sra_file = FALSE, trim_fastq = FALSE,
  trimmomatic_path = NULL, index_dir, species = c("human", "mouse", "rat"),
  countsFromAbundance = c("no", "scaledTPM", "lengthScaledTPM"),
  n_thread = 2)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{geo\_series\_acc}] GEO series accession ID.

\item[\code{destdir}] directory where all the results will be saved.

\item[\code{ascp}] logical, whether to use Aspera connect to download SRA run files. If FALSE, then wget will be used to download files which might be slower than \code{'ascp'} download.

\item[\code{prefetch\_workspace}] directory where SRA run files will be downloaded. This parameter is needed when \code{ascp=TRUE}. 
The location of this directory can be found by going to the aspera directory (/.aspera/connect/bin/) and typing \code{'vdb-config -i'}.
A new window will pop-up and under the \code{'Workspace Name'}, you will find the location. Usually the default is \code{'/home/username/ncbi/public'}.

\item[\code{ascp\_path}] path to the Aspera software.

\item[\code{get\_sra\_file}] logical, whether to download SRA file first and get fastq files afterwards.

\item[\code{trim\_fastq}] logical, whether to trim fastq file.

\item[\code{trimmomatic\_path}] path to Trimmomatic software.

\item[\code{index\_dir}] directory of the indexing files needed for read mapping using Salmon. See \LinkA{build\_index}{build.Rul.index}.

\item[\code{species}] name of the species. Only \code{'human'}, \code{'mouse'}, and \code{'rat'} are allowed to use.

\item[\code{countsFromAbundance}] whether to generate counts based on abundance. Available options are: \code{'no'}, 
\code{'scaledTPM'} (abundance based estimated counts scaled up to library size), 
\code{'lengthScaledTPM'} (default, scaled using the average transcript length over samples and library size). See Bioconductor package \LinkA{tximport}{tximport} for further details.

\item[\code{n\_thread}] number of cores to use.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a list of metadata from GEO and SRA saved in the \code{destdir}. Another list of gene and transcript level estimated counts summarized by 
Bioconductor package \code{'tximport'} is also saved in the \code{destdir}.
\end{Value}
%
\begin{References}\relax
Rob Patro, Geet Duggal, Michael I. Love, Rafael A. Irizarry, and Carl Kingsford (2017):
Salmon provides fast and bias-aware quantification of transcript expression. Nature methods, 14(4), 417.
\url{https://www.nature.com/articles/nmeth.4197}

Charlotte Soneson, Michael I. Love, Mark D. Robinson (2015):
Differential analyses for RNA-seq: transcript-level estimates
improve gene-level inferences. F1000Research.
\url{http://dx.doi.org/10.12688/f1000research.7563.1}

Philip Ewels, Mans Magnusson, Sverker Lundin, and Max Kaller (2016):
MultiQC: summarize analysis results for multiple tools and samples 
in a single report. Bioinformatics, 32(19), 3047-3048.
\url{https://doi.org/10.1093/bioinformatics/btw354}
\end{References}
%
\begin{Examples}
\begin{ExampleCode}
process_geo_rnaseq (geo_series_acc="GSE107363", destdir=".", ascp=TRUE, 
prefetch_workspace="path_to_prefetch_workspace",ascp_path="path_to_aspera",
get_sra_file=FALSE, trim_fastq=FALSE, trimmomatic_path=NULL,index_dir="path_to_indexDir",
species="human", countsFromAbundance = "lengthScaledTPM", n_thread=2)

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{run\_fastqc}{QC report for each fastq files using FastQC}{run.Rul.fastqc}
%
\begin{Description}\relax
\code{run\_fastqc} HTML report of each fastq files using FastQC. You need to install FastQC from \url{https://www.bioinformatics.babraham.ac.uk/projects/fastqc/}
\end{Description}
%
\begin{Usage}
\begin{verbatim}
run_fastqc(destdir, fastq_dir, n_thread)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{destdir}] directory where all the results will be saved.

\item[\code{fastq\_dir}] directory of the fastq files.

\item[\code{n\_thread}] number of cores to use.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
HTML report of the fastq files under fastqc directory.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}

run_fastqc(destdir=".", fastq_dir="path_to_fastq_dir", n_thread=2)

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{run\_multiqc}{Generate combined QC report for Salmon and FastQC}{run.Rul.multiqc}
%
\begin{Description}\relax
\code{run\_fastqc} generates a single HTML report from the fastQC reports and salmon read mapping results using MultiQC.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
run_multiqc(fastqc_dir, salmon_dir, destdir)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{fastqc\_dir}] directory where all the FastQC files are saved.

\item[\code{salmon\_dir}] directory of the salmon files.

\item[\code{destdir}] directory where you want to save the combined QC report.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
HTML report.
\end{Value}
%
\begin{References}\relax
Philip Ewels, Mans Magnusson, Sverker Lundin, and Max Kaller (2016):
MultiQC: summarize analysis results for multiple tools and samples 
in a single report. Bioinformatics, 32(19), 3047-3048.
\url{https://doi.org/10.1093/bioinformatics/btw354}
\end{References}
%
\begin{Examples}
\begin{ExampleCode}

run_fastqc(destdir=".", fastq_dir="path_to_fatsq_dir", n_thread=2)

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{run\_salmon}{Quantify transcript abundances using Salmon}{run.Rul.salmon}
%
\begin{Description}\relax
\code{run\_salmon} is a wrapper function for mapping reads to quantify transcript abundances using Salmon. You need to install Salmon and build index to run this function. 
For index building see \LinkA{build\_index}{build.Rul.index}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
run_salmon(srr_id, library_layout = c("SINGLE", "PAIRED"), index_dir, destdir,
  fastq_dir, use_trimmed_fastq = FALSE, other_opts = NULL, n_thread)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{srr\_id}] SRA run accession ID.

\item[\code{library\_layout}] layout of the library used. Either \code{'SINGLE'} or \code{'PAIRED'}.

\item[\code{index\_dir}] directory of the indexing files needed for read mapping using Salmon. See \LinkA{build\_index}{build.Rul.index}.

\item[\code{destdir}] directory where all the results will be saved.

\item[\code{fastq\_dir}] directory of the fastq files.

\item[\code{use\_trimmed\_fastq}] logical, whether to use trimmed fastq files.

\item[\code{other\_opts}] Other options to use. See Salmon documentation for the available options.

\item[\code{n\_thread}] number of cores to use.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
\code{run\_salmon} We use default options of Salmon. This function works for a single sample. You can use this function in a loop for multiple samples. 
For other options from Salmon use \code{'other\_opts'}.
\end{Details}
%
\begin{Value}
The following items will be returned and saved in the salmon directory:
\begin{enumerate}

\item quant\_new.sf: plain-text, tab-separated quantification file that contains 5 column: Name,Length,EffectiveLength,TPM, and NumReads.
\item cmd\_info.json: A JSON format file that records the main command line parameters with which Salmon was invoked for the run that produced the output in this directory.
\item aux\_info: This directory will have a number of files (and subfolders) depending on how salmon was invoked.
\item meta\_info.json: A JSON file that contains meta information about the run, including stats such as the number of observed and mapped fragments, details of the bias modeling etc. 
\item ambig\_info.tsv: This file contains information about the number of uniquely-mapping reads as well as the total number of ambiguously-mapping reads for each transcript. 
\item lib\_format\_counts.json: This JSON file reports the number of fragments that had at least one mapping compatible with the designated library format, as well as the number that didn't. 
\item libParams: The auxiliary directory will contain a text file called flenDist.txt. This file contains an approximation of the observed fragment length distribution.

\end{enumerate}

\end{Value}
%
\begin{References}\relax
Rob Patro, Geet Duggal, Michael I. Love, Rafael A. Irizarry, and Carl Kingsford (2017):
Salmon provides fast and bias-aware quantification of transcript expression. Nature methods, 14(4), 417.
\url{https://www.nature.com/articles/nmeth.4197}
\end{References}
%
\begin{Examples}
\begin{ExampleCode}
run_salmon(srr_id="SRR6324192", library_layout="SINGLE", index_dir="path_to_index_dir",
destdir=".", fastq_dir="path_to_fastq_dir", use_trimmed_fastq=FALSE,
other_opts=NULL, n_thread=2)

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{run\_tximport}{Wrapper function to run tximport}{run.Rul.tximport}
%
\begin{Description}\relax
\code{run\_tximport} function runs tximport on transcript level abundances from Salmon to summarize to gene level. See Bioconductor package
\LinkA{tximport}{tximport} for details.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
run_tximport(srr_id, species = c("human", "mouse", "rat"), salmon_dir,
  countsFromAbundance = c("no", "scaledTPM", "lengthScaledTPM"))
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{srr\_id}] SRA run accession ID.

\item[\code{species}] name of the species. Only \code{'human'}, \code{'mouse'}, and \code{'rat'} are allowed to use.

\item[\code{salmon\_dir}] directory where salmon files are saved.

\item[\code{countsFromAbundance}] whether to generate counts based on abundance. Available options are: \code{'no'}, 
\code{'scaledTPM'} (abundance based estimated counts scaled up to library size), 
\code{'lengthScaledTPM'} (default, scaled using the average transcript length over samples and library size).
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
We use Ensembl annotation for both genes and transcripts.
\end{Details}
%
\begin{Value}
a list of gene and transcript level estimated counts.
\end{Value}
%
\begin{References}\relax
Charlotte Soneson, Michael I. Love, Mark D. Robinson (2015):
Differential analyses for RNA-seq: transcript-level estimates
improve gene-level inferences. F1000Research.
\url{http://dx.doi.org/10.12688/f1000research.7563.1}
\end{References}
%
\begin{Examples}
\begin{ExampleCode}
run_tximport(srr_id="SRR6324192", species="human", salmon_dir="path_to_salmon_files_dir", 
countsFromAbundance = "lengthScaledTPM")

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{trim\_fastq}{Trim fastq files using Trimmomatic}{trim.Rul.fastq}
%
\begin{Description}\relax
\code{trim\_fastq} trim fastq files based on the illumina instruments using Trimmomatic.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
trim_fastq(srr_id, fastq_dir, instrument, trimmomatic_path,
  library_layout = c("SINGLE", "PAIRED"), n_thread)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{srr\_id}] SRA run accession ID.

\item[\code{fastq\_dir}] directory of the fastq files.

\item[\code{instrument}] name of the illumina sequencing platform. For example, \code{'HiSeq'}.

\item[\code{trimmomatic\_path}] path to the Trimmomatic software.

\item[\code{library\_layout}] layout of the library used. Either \code{'SINGLE'} or \code{'PAIRED'}.

\item[\code{n\_thread}] number of cores.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The following parameters are used as default in the trimmoatic function:
\begin{enumerate}

\item Remove leading low quality or N bases (below quality 3) (LEADING:3)
\item Remove trailing low quality or N bases (below quality 3) (TRAILING:3)
\item Scan the read with a 4-base wide sliding window, cutting when the average quality per base drops below 15 (SLIDINGWINDOW:4:15)
\item Drop reads below the 36 bases long (MINLEN:36)

\end{enumerate}

\end{Details}
%
\begin{Value}
trimmed fastq files.
\end{Value}
%
\begin{References}\relax
Anthony M. Bolger, Marc Lohse, and Bjoern Usadel (2014):
Trimmomatic: a flexible trimmer for Illumina sequence data. Bioinformatics, 30(15), 2114-2120.
\url{https://doi.org/10.1093/bioinformatics/btu170}
\end{References}
%
\begin{Examples}
\begin{ExampleCode}

trim_fastq(srr_id="SRR6324192", fastq_dir=".", instrument="HiSeq", 
trimmomatic_path="path_to_trimmomtic", library_layout="SINGLE", n_thread=2)

\end{ExampleCode}
\end{Examples}
\printindex{}
\end{document}
